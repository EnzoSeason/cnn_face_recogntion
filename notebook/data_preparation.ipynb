{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "In this notebook, we will prepare the data for training our face recogntion model.\n",
    "\n",
    "We split data into 2 set.\n",
    "* training set: first 600 images\n",
    "* Validation set: last 400 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â ## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from skimage import io, util, color, transform\n",
    "\n",
    "from statistics import mode\n",
    "\n",
    "sys.path.append('../src')\n",
    "import data_utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the postive data\n",
    "\n",
    "We crop the face in the training set, and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.loadtxt('../data/project_train/label.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get orginal images\n",
    "img_raw = []\n",
    "n_total = 1000\n",
    "for i in range(n_total):\n",
    "    im = color.rgb2gray(io.imread(\"../data/project_train/train/\" + \"%04d\"%(i+1) + \".jpg\"))\n",
    "    im = util.img_as_float(im)\n",
    "    img_raw.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get face images\n",
    "img_target = []\n",
    "img_train = []\n",
    "img_validation = []\n",
    "for img in label:\n",
    "    idx = int(img[0])\n",
    "    o_h = int(img[1])\n",
    "    o_l = int(img[2])\n",
    "    h = int(img[3])\n",
    "    l = int(img[4])\n",
    "    sub_img = img_raw[idx-1][o_h :o_h + h, o_l : o_l + l]\n",
    "    img_target.append(sub_img)\n",
    "    if idx > 600:\n",
    "        img_validation.append(sub_img)\n",
    "    else:\n",
    "        img_train.append(sub_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.519537040270022"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_hl = np.mean(label[:,3]/label[:,4])\n",
    "mean_hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_HL = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80, 120\n"
     ]
    }
   ],
   "source": [
    "# create detector box with fixed size\n",
    "l_fixed = int(mode(label[:,4]))+1\n",
    "h_fixed = int(ratio_HL * l_fixed)\n",
    "print('{}, {}'.format(l_fixed, h_fixed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_pos = []\n",
    "\n",
    "for img in img_train:\n",
    "    im = transform.resize(img,(h_fixed,l_fixed))\n",
    "    data_train_pos.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771, 120, 80)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_pos = np.array(data_train_pos)\n",
    "data_train_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/output/data_set/data_train_pos', data_train_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation_pos = []\n",
    "\n",
    "for img in img_validation:\n",
    "    im = transform.resize(img,(h_fixed,l_fixed))\n",
    "    data_validation_pos.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 120, 80)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_validation_pos = np.array(data_validation_pos)\n",
    "data_validation_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/output/data_set/data_validation_pos', data_validation_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the negative data\n",
    "\n",
    "We crop image randomly with the size of the detector box. If the cover area between the cropped image and one of the face images > 0.1 (the status of being completely covered represent by 1), then the cropped image isn't a negative example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_neg = []\n",
    "for i in range(len(img_raw[0:600])):\n",
    "    H = img_raw[i].shape[0]\n",
    "    L = img_raw[i].shape[1]\n",
    "    image = img_raw[i]\n",
    "    exemples_pos = []\n",
    "    for face in label:\n",
    "        if face[0] == i+1:\n",
    "            exemples_pos.append(face)\n",
    "    nb_img_neg = 0\n",
    "    while nb_img_neg < 10:\n",
    "        position_h = int(np.random.uniform(0,H))\n",
    "        position_l = int(np.random.uniform(0,L))\n",
    "        # h and l need to be fine-tined\n",
    "        h = int(np.random.uniform(int(H/5),int(H/2))) \n",
    "        l = int(h/ratio_HL)\n",
    "        img_atr = np.array([position_h, position_l, h, l])\n",
    "        is_pos = False\n",
    "        for face in exemples_pos:\n",
    "            aire_re = data_utils.calcul_aire_recouvrement(face[1:5], img_atr)\n",
    "            if aire_re > 0.1:\n",
    "                is_pos = True\n",
    "        if is_pos == False:\n",
    "            img_neg = image[position_h: position_h + h, position_l: position_l + l]\n",
    "            img_neg = transform.resize(img_neg, (h_fixed, l_fixed))\n",
    "            data_train_neg.append(img_neg)\n",
    "            nb_img_neg += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_neg = np.array(data_train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 120, 80)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/output/data_set/data_train_neg', data_train_neg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cnn_face_recogntion)",
   "language": "python",
   "name": "cnn_face_recogntion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
